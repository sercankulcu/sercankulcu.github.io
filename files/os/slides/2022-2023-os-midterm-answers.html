<script type="text/javascript">
        var gk_isXlsx = false;
        var gk_xlsxFileLookup = {};
        var gk_fileData = {};
        function filledCell(cell) {
          return cell !== '' && cell != null;
        }
        function loadFileData(filename) {
        if (gk_isXlsx && gk_xlsxFileLookup[filename]) {
            try {
                var workbook = XLSX.read(gk_fileData[filename], { type: 'base64' });
                var firstSheetName = workbook.SheetNames[0];
                var worksheet = workbook.Sheets[firstSheetName];

                // Convert sheet to JSON to filter blank rows
                var jsonData = XLSX.utils.sheet_to_json(worksheet, { header: 1, blankrows: false, defval: '' });
                // Filter out blank rows (rows where all cells are empty, null, or undefined)
                var filteredData = jsonData.filter(row => row.some(filledCell));

                // Heuristic to find the header row by ignoring rows with fewer filled cells than the next row
                var headerRowIndex = filteredData.findIndex((row, index) =>
                  row.filter(filledCell).length >= filteredData[index + 1]?.filter(filledCell).length
                );
                // Fallback
                if (headerRowIndex === -1 || headerRowIndex > 25) {
                  headerRowIndex = 0;
                }

                // Convert filtered JSON back to CSV
                var csv = XLSX.utils.aoa_to_sheet(filteredData.slice(headerRowIndex)); // Create a new sheet from filtered array of arrays
                csv = XLSX.utils.sheet_to_csv(csv, { header: 1 });
                return csv;
            } catch (e) {
                console.error(e);
                return "";
            }
        }
        return gk_fileData[filename] || "";
        }
        </script><!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Operating Systems Midterm Exam Questions and Answers</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            background-color: #f4f4f4;
            margin: 0;
            padding: 20px;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
        }
        h1 {
            font-size: 2.5em;
            text-align: center;
            color: #333;
            margin-bottom: 20px;
        }
        p.subtitle {
            font-size: 1.2em;
            text-align: center;
            color: #555;
            margin-bottom: 30px;
        }
        .question {
            background-color: #fff;
            padding: 20px;
            margin-bottom: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
        }
        .question h2 {
            font-size: 1.5em;
            color: #2c3e50;
            margin-bottom: 15px;
        }
        .question p {
            font-size: 1em;
            color: #333;
            line-height: 1.6;
            margin-bottom: 10px;
        }
        .question ul {
            list-style-type: disc;
            padding-left: 30px;
            margin-bottom: 10px;
        }
        .question ul li {
            font-size: 1em;
            color: #333;
            margin-bottom: 5px;
        }
        .question p.key-concepts {
            font-style: italic;
            color: #666;
            margin-top: 10px;
        }
        strong {
            color: #2c3e50;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Giresun University Operating Systems Midterm Exam (2022-2023)</h1>
        <p class="subtitle">Detailed answers for Computer Science students</p>

        <!-- Question 1 -->
        <div class="question">
            <h2>1. Which of the following memory management techniques does not involve dynamic memory allocation?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Paging</li>
                <li>b) Segmentation</li>
                <li>c) Virtual memory</li>
                <li>d) Fixed partitioning</li>
            </ul>
            <p><strong>Answer:</strong> d) Fixed partitioning</p>
            <p><strong>Explanation:</strong> <strong>Fixed partitioning</strong> divides physical memory into static, predetermined partitions at system startup, and each partition is allocated to a process without resizing during execution. This lacks dynamic allocation, as memory is pre-allocated. In contrast, <strong>paging</strong> dynamically allocates fixed-size pages, <strong>segmentation</strong> allocates variable-sized segments, and <strong>virtual memory</strong> dynamically manages memory using paging or swapping. Fixed partitioning is rigid, often leading to internal fragmentation.</p>
            <p class="key-concepts">Key Concepts: Fixed partitioning, dynamic allocation, paging, segmentation, virtual memory.</p>
        </div>

        <!-- Question 2 -->
        <div class="question">
            <h2>2. Which of the following scheduling algorithms can result in starvation?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Round-robin</li>
                <li>b) Priority scheduling</li>
                <li>c) First-come, first-served</li>
                <li>d) Shortest job first</li>
            </ul>
            <p><strong>Answer:</strong> b) Priority scheduling</p>
            <p><strong>Explanation:</strong> <strong>Starvation</strong> occurs when a process is perpetually denied CPU time because higher-priority processes keep arriving. <strong>Priority scheduling</strong> can cause starvation for low-priority processes if high-priority processes dominate. <strong>Round-robin</strong> ensures fair time slices, preventing starvation. <strong>First-come, first-served (FCFS)</strong> and <strong>Shortest job first (SJF)</strong> may cause delays but typically don’t lead to indefinite starvation, as all processes eventually run.</p>
            <p class="key-concepts">Key Concepts: Starvation, priority scheduling, fairness, scheduling algorithms.</p>
        </div>

        <!-- Question 3 -->
        <div class="question">
            <h2>3. Which of the following scheduling algorithms can lead to the convoy effect?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Round-robin</li>
                <li>b) Priority scheduling</li>
                <li>c) First-come, first-served</li>
                <li>d) Shortest job first</li>
            </ul>
            <p><strong>Answer:</strong> c) First-come, first-served</p>
            <p><strong>Explanation:</strong> The <strong>convoy effect</strong> occurs when a long-running process holds the CPU, causing shorter processes to wait, increasing average waiting time. <strong>First-come, first-served (FCFS)</strong> executes processes in arrival order, so a CPU-intensive process can block others, creating a "convoy." <strong>Round-robin</strong> avoids this with time slices, <strong>Priority scheduling</strong> prioritizes based on importance, and <strong>Shortest job first</strong> favors short processes, reducing the convoy effect.</p>
            <p class="key-concepts">Key Concepts: Convoy effect, FCFS, scheduling, waiting time.</p>
        </div>

        <!-- Question 4 -->
        <div class="question">
            <h2>4. Which of the following is not a primary function of an operating system?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Memory management</li>
                <li>b) Input/output management</li>
                <li>c) User interface design</li>
                <li>d) Process management</li>
            </ul>
            <p><strong>Answer:</strong> c) User interface design</p>
            <p><strong>Explanation:</strong> An operating system’s primary functions include <strong>memory management</strong> (allocating memory), <strong>input/output management</strong> (handling devices), and <strong>process management</strong> (scheduling and synchronization). <strong>User interface design</strong> is typically handled by applications or desktop environments (e.g., GNOME, Windows Explorer), not the OS core, though some OSes provide basic UI components.</p>
            <p class="key-concepts">Key Concepts: OS functions, memory management, I/O management, process management.</p>
        </div>

        <!-- Question 5 -->
        <div class="question">
            <h2>5. Which of the following is not a type of system call?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) File operations</li>
                <li>b) Memory allocation</li>
                <li>c) I/O device operations</li>
                <li>d) Data encryption</li>
            </ul>
            <p><strong>Answer:</strong> d) Data encryption</p>
            <p><strong>Explanation:</strong> <strong>System calls</strong> are interfaces for user programs to request OS services, including <strong>file operations</strong> (e.g., open, read), <strong>memory allocation</strong> (e.g., malloc), and <strong>I/O device operations</strong> (e.g., ioctl). <strong>Data encryption</strong> is typically handled by libraries or applications, not as a direct system call, though some OSes may provide encryption-related services indirectly.</p>
            <p class="key-concepts">Key Concepts: System calls, file operations, memory allocation, I/O operations.</p>
        </div>

        <!-- Question 6 -->
        <div class="question">
            <h2>6. Which of Ascending-descending (blocked) is not a process state?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Running</li>
                <li>b) Ready</li>
                <li>c) Blocked</li>
                <li>d) Active</li>
            </ul>
            <p><strong>Answer:</strong> d) Active</p>
            <p><strong>Explanation:</strong> A process can be in states like <strong>Running</strong> (executing on CPU), <strong>Ready</strong> (waiting for CPU), or <strong>Blocked</strong> (waiting for an event, e.g., I/O). <strong>Active</strong> is not a standard process state in OS terminology; it’s a vague term sometimes used informally but not part of the process state model.</p>
            <p class="key-concepts">Key Concepts: Process states, running, ready, blocked.</p>
        </div>

        <!-- Question 7 -->
        <div class="question">
            <h2>7. Which of the following is not a type of process scheduling algorithm?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Round-robin</li>
                <li>b) Priority scheduling</li>
                <li>c) First-come, first-served (FCFS)</li>
                <li>d) Concurrent scheduling</li>
            </ul>
            <p><strong>Answer:</strong> d) Concurrent scheduling</p>
            <p><strong>Explanation:</strong> <strong>Round-robin</strong>, <strong>Priority scheduling</strong>, and <strong>FCFS</strong> are standard scheduling algorithms. <strong>Concurrent scheduling</strong> is not a recognized scheduling algorithm; concurrency refers to simultaneous execution, not a specific scheduling method.</p>
            <p class="key-concepts">Key Concepts: Scheduling algorithms, round-robin, priority scheduling, FCFS.</p>
        </div>

        <!-- Question 8 -->
        <div class="question">
            <h2>8. Which of the following is not a benefit of using threads within a process?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Improved performance through parallel execution</li>
                <li>b) Better utilization of processor resources</li>
                <li>c) Easier communication and coordination between threads</li>
                <li>d) Increased reliability due to reduced dependency on external processes</li>
            </ul>
            <p><strong>Answer:</strong> d) Increased reliability due to reduced dependency on external processes</p>
            <p><strong>Explanation:</strong> Threads within a process enable <strong>parallel execution</strong> (improving performance), <strong>better resource utilization</strong> (sharing memory), and <strong>easier communication</strong> (via shared memory). <strong>Increased reliability</strong> is not a direct benefit, as threads share the same address space, and a thread failure can crash the entire process, not reducing dependency on external processes.</p>
            <p class="key-concepts">Key Concepts: Threads, parallel execution, resource utilization, communication.</p>
        </div>

        <!-- Question 9 -->
        <div class="question">
            <h2>9. Which of the following is not a common metric used to evaluate scheduling algorithms?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Average waiting time</li>
                <li>b) Average turnaround time</li>
                <li>c) Processor utilization</li>
                <li>d) Disk I/O throughput</li>
            </ul>
            <p><strong>Answer:</strong> d) Disk I/O throughput</p>
            <p><strong>Explanation:</strong> Scheduling algorithms are evaluated using metrics like <strong>average waiting time</strong> (time spent waiting for CPU), <strong>average turnaround time</strong> (total time from submission to completion), and <strong>processor utilization</strong> (CPU usage efficiency). <strong>Disk I/O throughput</strong> measures storage performance, not CPU scheduling effectiveness.</p>
            <p class="key-concepts">Key Concepts: Scheduling metrics, waiting time, turnaround time, processor utilization.</p>
        </div>

        <!-- Question 10 -->
        <div class="question">
            <h2>10. Which of the following is not a common issue related to concurrent execution?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Deadlocks</li>
                <li>b) Starvation</li>
                <li>c) Livelocks</li>
                <li>d) Monopolies</li>
            </ul>
            <p><strong>Answer:</strong> d) Monopolies</p>
            <p><strong>Explanation:</strong> Concurrent execution issues include <strong>deadlocks</strong> (processes blocked waiting for resources), <strong>starvation</strong> (processes denied resources), and <strong>livelocks</strong> (processes stuck in a loop of state changes). <strong>Monopolies</strong> is not a standard term in concurrency; it may refer to resource hogging but isn’t a recognized issue.</p>
            <p class="key-concepts">Key Concepts: Concurrency issues, deadlocks, starvation, livelocks.</p>
        </div>

        <!-- Question 11 -->
        <div class="question">
            <h2>11. Which of the following is not a benefit of using thread pools?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Improved performance due to reduced overhead</li>
                <li>b) Improved resource utilization</li>
                <li>c) Easier thread management</li>
                <li>d) Increased flexibility due to dynamic thread creation</li>
            </ul>
            <p><strong>Answer:</strong> d) Increased flexibility due to dynamic thread creation</p>
            <p><strong>Explanation:</strong> <strong>Thread pools</strong> reuse a fixed set of threads, reducing overhead (<strong>improved performance</strong>), optimizing resource use (<strong>improved utilization</strong>), and simplifying management (<strong>easier management</strong>). <strong>Dynamic thread creation</strong> is not a benefit, as thread pools limit creation to a predefined size, sacrificing flexibility for efficiency.</p>
            <p class="key-concepts">Key Concepts: Thread pools, overhead, resource utilization, thread management.</p>
        </div>

        <!-- Question 12 -->
        <div class="question">
            <h2>12. Which of the following is not a commonly used synchronization mechanism in operating systems?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Semaphores</li>
                <li>b) Mutexes</li>
                <li>c) Condition variables</li>
                <li>d) Shared memory</li>
            </ul>
            <p><strong>Answer:</strong> d) Shared memory</p>
            <p><strong>Explanation:</strong> <strong>Semaphores</strong>, <strong>mutexes</strong>, and <strong>condition variables</strong> are synchronization mechanisms used to coordinate access to shared resources. <strong>Shared memory</strong> is a mechanism for inter-process communication, not synchronization, as it requires additional synchronization tools to manage access.</p>
            <p class="key-concepts">Key Concepts: Synchronization, semaphores, mutexes, condition variables.</p>
        </div>

        <!-- Question 13 -->
        <div class="question">
            <h2>13. Which of the following is not a commonly used synchronization primitive in operating systems?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Semaphores</li>
                <li>b) Mutexes</li>
                <li>c) Monitors</li>
                <li>d) Registers</li>
            </ul>
            <p><strong>Answer:</strong> d) Registers</p>
            <p><strong>Explanation:</strong> <strong>Semaphores</strong>, <strong>mutexes</strong>, and <strong>monitors</strong> are synchronization primitives for coordinating shared resource access. <strong>Registers</strong> are CPU hardware components for data storage, not used for synchronization.</p>
            <p class="key-concepts">Key Concepts: Synchronization primitives, semaphores, mutexes, monitors.</p>
        </div>

        <!-- Question 14 -->
        <div class="question">
            <h2>14. Which of the following is a commonly used technique to prevent deadlocks?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Resource allocation graph</li>
                <li>b) Priority inversion</li>
                <li>c) Spinning</li>
                <li>d) Busy waiting</li>
            </ul>
            <p><strong>Answer:</strong> None (Correct answer missing; likely meant to include Banker’s Algorithm)</p>
            <p><strong>Explanation:</strong> The options listed do not include a standard deadlock prevention technique. <strong>Resource allocation graph</strong> is used for detection, not prevention. <strong>Priority inversion</strong> is a problem, not a solution. <strong>Spinning</strong> and <strong>busy waiting</strong> are inefficient synchronization methods. A correct option would be the <strong>Banker’s Algorithm</strong>, which prevents deadlocks by ensuring safe resource allocation states.</p>
            <p class="key-concepts">Key Concepts: Deadlock prevention, Banker’s Algorithm, resource allocation.</p>
        </div>

        <!-- Question 15 -->
        <div class="question">
            <h2>15. Which of the following is not a condition for a deadlock to occur?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Mutual exclusion</li>
                <li>b) Hold and wait</li>
                <li>c) No preemption</li>
                <li>d) Unlimited resources</li>
            </ul>
            <p><strong>Answer:</strong> d) Unlimited resources</p>
            <p><strong>Explanation:</strong> Deadlocks require four conditions: <strong>mutual exclusion</strong> (resources held exclusively), <strong>hold and wait</strong> (processes holding resources while waiting), <strong>no preemption</strong> (resources cannot be forcibly taken), and <strong>circular wait</strong> (processes form a cycle). <strong>Unlimited resources</strong> would prevent deadlocks, as resource contention wouldn’t occur.</p>
            <p class="key-concepts">Key Concepts: Deadlock conditions, mutual exclusion, hold and wait, no preemption.</p>
        </div>

        <!-- Question 16 -->
        <div class="question">
            <h2>16. Which of the following is not an advantage of using a microkernel architecture?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Modularity and ease of development</li>
                <li>b) More efficient inter-process communication (IPC)</li>
                <li>c) Better security and reliability</li>
                <li>d) More efficient memory management</li>
            </ul>
            <p><strong>Answer:</strong> b) More efficient inter-process communication (IPC)</p>
            <p><strong>Explanation:</strong> <strong>Microkernel</strong> architectures offer <strong>modularity</strong> (easier to develop and maintain), <strong>better security/reliability</strong> (isolated components), and potentially <strong>efficient memory management</strong>. However, <strong>IPC</strong> is less efficient due to message passing between user-space services, unlike monolithic kernels’ direct function calls.</p>
            <p class="key-concepts">Key Concepts: Microkernel, modularity, IPC, security.</p>
        </div>

        <!-- Question 17 -->
        <div class="question">
            <h2>17. Which of the following is not a characteristic of a monolithic kernel?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) All kernel functions implemented in a single address space</li>
                <li>b) Kernel code loaded as a single binary file</li>
                <li>c) Kernel is modular and easily extensible</li>
                <li>d) Kernel provides all system services directly to applications</li>
            </ul>
            <p><strong>Answer:</strong> c) Kernel is modular and easily extensible</p>
            <p><strong>Explanation:</strong> A <strong>monolithic kernel</strong> runs all functions in a single address space (<strong>a</strong>), is loaded as a single binary (<strong>b</strong>), and provides services directly (<strong>d</strong>). However, it is not inherently <strong>modular or easily extensible</strong>, as its tightly coupled design makes modifications complex compared to microkernels.</p>
            <p class="key-concepts">Key Concepts: Monolithic kernel, address space, modularity.</p>
        </div>

        <!-- Question 18 -->
        <div class="question">
            <h2>18. Which of the following is not a component of the Process Control Block (PCB)?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Process state</li>
                <li>b) Process ID</li>
                <li>c) Memory allocation</li>
                <li>d) CPU scheduling information</li>
            </ul>
            <p><strong>Answer:</strong> c) Memory allocation</p>
            <p><strong>Explanation:</strong> The <strong>PCB</strong> contains <strong>process state</strong> (e.g., running), <strong>process ID</strong>, and <strong>CPU scheduling information</strong> (e.g., priority). <strong>Memory allocation</strong> is managed by the OS’s memory management system, not stored directly in the PCB, though the PCB may reference memory-related data (e.g., page tables).</p>
            <p class="key-concepts">Key Concepts: Process Control Block, process state, process ID, scheduling.</p>
        </div>

        <!-- Question 19 -->
        <div class="question">
            <h2>19. Which of the following is not a process state in the process life cycle?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Running</li>
                <li>b) Blocked</li>
                <li>c) Suspended</li>
                <li>d) Terminated</li>
            </ul>
            <p><strong>Answer:</strong> c) Suspended</p>
            <p><strong>Explanation:</strong> Standard process states include <strong>Running</strong>, <strong>Blocked</strong>, <strong>Ready</strong>, <strong>New</strong>, and <strong>Terminated</strong>. <strong>Suspended</strong> is sometimes used in specific OSes (e.g., swapped out to disk), but it’s not a universal state in the standard process life cycle model.</p>
            <p class="key-concepts">Key Concepts: Process life cycle, process states, running, blocked, terminated.</p>
        </div>

        <!-- Question 20 -->
        <div class="question">
            <h2>20. Which of the following is not a type of inter-process communication (IPC) mechanism?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Shared memory</li>
                <li>b) Message passing</li>
                <li>c) Pipe</li>
                <li>d) Interrupts</li>
            </ul>
            <p><strong>Answer:</strong> d) Interrupts</p>
            <p><strong>Explanation:</strong> IPC mechanisms include <strong>shared memory</strong> (processes share a memory region), <strong>message passing</strong> (data exchange via messages), and <strong>pipes</strong> (unidirectional data channels). <strong>Interrupts</strong> are hardware signals for event handling, not an IPC mechanism.</p>
            <p class="key-concepts">Key Concepts: IPC, shared memory, message passing, pipes.</p>
        </div>

        <!-- Question 21 -->
        <div class="question">
            <h2>21. Which of the following is not a common thread-related issue?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Deadlock</li>
                <li>b) Live lock</li>
                <li>c) Race condition</li>
                <li>d) Concurrent modification</li>
            </ul>
            <p><strong>Answer:</strong> d) Concurrent modification</p>
            <p><strong>Explanation:</strong> Thread issues include <strong>deadlock</strong> (threads blocked waiting), <strong>live lock</strong> (threads stuck in a loop), and <strong>race condition</strong> (unpredictable outcomes from unsynchronized access). <strong>Concurrent modification</strong> is a specific issue in some contexts (e.g., Java collections), but it’s not a standard thread issue term; it’s a consequence of race conditions.</p>
            <p class="key-concepts">Key Concepts: Thread issues, deadlock, live lock, race condition.</p>
        </div>

        <!-- Question 22 -->
        <div class="question">
            <h2>22. Which of the following is true about device drivers?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) They are part of the operating system kernel</li>
                <li>b) They run in user mode</li>
                <li>c) They are used for inter-process communication</li>
                <li>d) They are used to manage the process life cycle</li>
            </ul>
            <p><strong>Answer:</strong> a) They are part of the operating system kernel</p>
            <p><strong>Explanation:</strong> <strong>Device drivers</strong> are kernel components that interface between the OS and hardware devices, running in kernel mode for direct hardware access. They don’t run in <strong>user mode</strong>, aren’t used for <strong>IPC</strong>, and don’t manage <strong>process life cycles</strong>.</p>
            <p class="key-concepts">Key Concepts: Device drivers, kernel mode, hardware interface.</p>
        </div>

        <!-- Question 23 -->
        <div class="question">
            <h2>23. What is the fundamental difference between a process and a thread?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) A process has its own memory space, while threads share the same memory space</li>
                <li>b) A process can run on multiple processors, while a thread can only run on a single processor</li>
                <li>c) A process can have multiple threads, while a thread can only belong to a single process</li>
                <li>d) Processes can directly access hardware, while threads cannot</li>
            </ul>
            <p><strong>Answer:</strong> a) A process has its own memory space, while threads share the same memory space</p>
            <p><strong>Explanation:</strong> A <strong>process</strong> has its own address space, while <strong>threads</strong> within a process share the same memory and resources, differing only in their execution context (stack, registers). <strong>Option b</strong> is incorrect, as both can run on multiple processors. <strong>Option c</strong> is true but not the fundamental difference. <strong>Option d</strong> is false, as neither directly accesses hardware.</p>
            <p class="key-concepts">Key Concepts: Process, thread, memory space, resource sharing.</p>
        </div>

        <!-- Question 24 -->
        <div class="question">
            <h2>24. Which scheduling algorithm is used in real-time operating systems?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Round-robin</li>
                <li>b) First-come, first-served</li>
                <li>c) Shortest job first</li>
                <li>d) Earliest Deadline First</li>
            </ul>
            <p><strong>Answer:</strong> d) Earliest Deadline First</p>
            <p><strong>Explanation:</strong> <strong>Earliest Deadline First (EDF)</strong> is used in real-time OSes, prioritizing tasks with the closest deadlines to ensure timely execution, critical for real-time constraints. <strong>Round-robin</strong>, <strong>FCFS</strong>, and <strong>SJF</strong> are not deadline-aware, making them unsuitable for real-time systems.</p>
            <p class="key-concepts">Key Concepts: Real-time scheduling, EDF, deadlines.</p>
        </div>

        <!-- Question 25 -->
        <div class="question">
            <h2>25. Which of the following is true about interrupt handlers?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) They are part of the operating system kernel</li>
                <li>b) They run in user mode</li>
                <li>c) They cannot be interrupted</li>
                <li>d) They are used for inter-process communication</li>
            </ul>
            <p><strong>Answer:</strong> a) They are part of the operating system kernel</p>
            <p><strong>Explanation:</strong> <strong>Interrupt handlers</strong> are kernel components that process hardware interrupts, running in kernel mode. They can be interrupted (<strong>option c</strong> is false), don’t run in <strong>user mode</strong>, and aren’t used for <strong>IPC</strong>.</p>
            <p class="key-concepts">Key Concepts: Interrupt handlers, kernel mode, hardware interrupts.</p>
        </div>

        <!-- Question 26 -->
        <div class="question">
            <h2>26. What is the difference between mutexes and semaphores?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Mutexes are used for synchronization, while semaphores are used for mutual exclusion</li>
                <li>b) Mutexes are binary locks, while semaphores are integer counters</li>
                <li>c) Mutexes allow only one process to access a resource at a time, while semaphores allow multiple processes to access a resource simultaneously</li>
                <li>d) Mutexes are more efficient than semaphores in terms of system overhead</li>
            </ul>
            <p><strong>Answer:</strong> b) Mutexes are binary locks, while semaphores are integer counters</p>
            <p><strong>Explanation:</strong> <strong>Mutexes</strong> are binary locks (locked/unlocked) for mutual exclusion, ensuring one thread accesses a resource. <strong>Semaphores</strong> are counters, allowing multiple threads (if counting semaphore) or signaling (if binary). <strong>Option a</strong> reverses roles. <strong>Option c</strong> is partially true but not the key difference. <strong>Option d</strong> depends on implementation, not a defining trait.</p>
            <p class="key-concepts">Key Concepts: Mutexes, semaphores, mutual exclusion, signaling.</p>
        </div>

        <!-- Question 27 -->
        <div class="question">
            <h2>27. In a preemptive scheduling algorithm, when does context switching occur?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) When a process voluntarily yields the processor</li>
                <li>b) When a process is blocked waiting for I/O</li>
                <li>c) When a higher-priority process becomes ready</li>
                <li>d) When a lower-priority process becomes ready</li>
            </ul>
            <p><strong>Answer:</strong> c) When a higher-priority process becomes ready</p>
            <p><strong>Explanation:</strong> In <strong>preemptive scheduling</strong>, the OS interrupts a running process to switch to a higher-priority process that becomes ready (e.g., from blocked to ready). <strong>Voluntary yielding</strong> is non-preemptive. <strong>Blocking for I/O</strong> causes a switch but isn’t priority-driven. <strong>Lower-priority processes</strong> don’t preempt higher ones.</p>
            <p class="key-concepts">Key Concepts: Preemptive scheduling, context switching, priority.</p>
        </div>

        <!-- Question 28 -->
        <div class="question">
            <h2>28. Which of the following is true about process scheduling?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) It is responsible for allocating memory to processes</li>
                <li>b) It determines which process will use the processor next</li>
                <li>c) It manages inter-process communication</li>
                <li>d) It is used to manage I/O operations</li>
            </ul>
            <p><strong>Answer:</strong> b) It determines which process will use the processor next</p>
            <p><strong>Explanation:</strong> <strong>Process scheduling</strong> selects the next process to run on the CPU based on algorithms like Round-robin or Priority scheduling. <strong>Memory allocation</strong>, <strong>IPC</strong>, and <strong>I/O operations</strong> are handled by other OS components.</p>
            <p class="key-concepts">Key Concepts: Process scheduling, CPU allocation, scheduling algorithms.</p>
        </div>

        <!-- Question 29 -->
        <div class="question">
            <h2>29. Which of the following is true about process synchronization?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) It is used to manage the process life cycle</li>
                <li>b) It is used for allocating memory to processes</li>
                <li>c) It is used to manage inter-process communication</li>
                <li>d) It is used to coordinate access to shared resources</li>
            </ul>
            <p><strong>Answer:</strong> d) It is used to coordinate access to shared resources</p>
            <p><strong>Explanation:</strong> <strong>Process synchronization</strong> ensures orderly access to shared resources (e.g., using mutexes or semaphores) to prevent issues like race conditions. <strong>Process life cycle</strong>, <strong>memory allocation</strong>, and <strong>IPC</strong> are separate OS functions.</p>
            <p class="key-concepts">Key Concepts: Process synchronization, shared resources, race conditions.</p>
        </div>
    </div>
</body>
</html>