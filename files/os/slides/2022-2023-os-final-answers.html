<script type="text/javascript">
        var gk_isXlsx = false;
        var gk_xlsxFileLookup = {};
        var gk_fileData = {};
        function filledCell(cell) {
          return cell !== '' && cell != null;
        }
        function loadFileData(filename) {
        if (gk_isXlsx && gk_xlsxFileLookup[filename]) {
            try {
                var workbook = XLSX.read(gk_fileData[filename], { type: 'base64' });
                var firstSheetName = workbook.SheetNames[0];
                var worksheet = workbook.Sheets[firstSheetName];

                // Convert sheet to JSON to filter blank rows
                var jsonData = XLSX.utils.sheet_to_json(worksheet, { header: 1, blankrows: false, defval: '' });
                // Filter out blank rows (rows where all cells are empty, null, or undefined)
                var filteredData = jsonData.filter(row => row.some(filledCell));

                // Heuristic to find the header row by ignoring rows with fewer filled cells than the next row
                var headerRowIndex = filteredData.findIndex((row, index) =>
                  row.filter(filledCell).length >= filteredData[index + 1]?.filter(filledCell).length
                );
                // Fallback
                if (headerRowIndex === -1 || headerRowIndex > 25) {
                  headerRowIndex = 0;
                }

                // Convert filtered JSON back to CSV
                var csv = XLSX.utils.aoa_to_sheet(filteredData.slice(headerRowIndex)); // Create a new sheet from filtered array of arrays
                csv = XLSX.utils.sheet_to_csv(csv, { header: 1 });
                return csv;
            } catch (e) {
                console.error(e);
                return "";
            }
        }
        return gk_fileData[filename] || "";
        }
        </script><!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Operating Systems Final Exam Questions and Answers</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            background-color: #f4f4f4;
            margin: 0;
            padding: 20px;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
        }
        h1 {
            font-size: 2.5em;
            text-align: center;
            color: #333;
            margin-bottom: 20px;
        }
        p.subtitle {
            font-size: 1.2em;
            text-align: center;
            color: #555;
            margin-bottom: 30px;
        }
        .question {
            background-color: #fff;
            padding: 20px;
            margin-bottom: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
        }
        .question h2 {
            font-size: 1.5em;
            color: #2c3e50;
            margin-bottom: 15px;
        }
        .question p {
            font-size: 1em;
            color: #333;
            line-height: 1.6;
            margin-bottom: 10px;
        }
        .question ul {
            list-style-type: disc;
            padding-left: 30px;
            margin-bottom: 10px;
        }
        .question ul li {
            font-size: 1em;
            color: #333;
            margin-bottom: 5px;
        }
        .question p.key-concepts {
            font-style: italic;
            color: #666;
            margin-top: 10px;
        }
        strong {
            color: #2c3e50;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Giresun University Operating Systems Final Exam (2022-2023)</h1>
        <p class="subtitle">Detailed answers for Computer Science students</p>

        <!-- Question 1 -->
        <div class="question">
            <h2>1. How does an operating system enable multiple processes to run in parallel on a single-processor hardware? Explain briefly.</h2>
            <p><strong>Answer:</strong> The operating system achieves this through <strong>time-sharing</strong> and <strong>multitasking</strong>. It allocates the CPU to different processes in short time slices (called <strong>time quantum</strong>) using a scheduling algorithm, such as Round-robin. The OS performs <strong>context switching</strong> to save the state of one process (registers, program counter, etc.) and load another, creating the illusion of parallelism. This is known as <strong>preemptive multitasking</strong>. For example, a process runs for a few milliseconds before the OS switches to another process, ensuring responsiveness and efficient CPU utilization. This approach balances foreground tasks (e.g., user interfaces) with background tasks (e.g., system services).</p>
            <p class="key-concepts">Key Concepts: Time-sharing, context switching, preemptive multitasking, scheduling algorithms.</p>
        </div>

        <!-- Question 2 -->
        <div class="question">
            <h2>2. How does an operating system allow multiple processes to use more memory than physically available? Explain briefly.</h2>
            <p><strong>Answer:</strong> The operating system uses <strong>virtual memory</strong> to provide each process with a separate, abstract address space. Virtual addresses are mapped to physical memory via <strong>page tables</strong>, managed by the Memory Management Unit (MMU). When physical memory is insufficient, the OS employs <strong>paging</strong>, moving less-used pages to a disk-based <strong>swap space</strong> or page file. This process, called <strong>page swapping</strong>, allows processes to operate as if they have access to more memory than physically available. However, excessive swapping can lead to <strong>thrashing</strong>, where the system spends more time swapping pages than executing processes, degrading performance due to slower disk I/O compared to RAM.</p>
            <p class="key-concepts">Key Concepts: Virtual memory, paging, swap space, page tables, thrashing.</p>
        </div>

        <!-- Question 3 -->
        <div class="question">
            <h2>3. Which scheduling algorithm prioritizes processes based on their expected execution time?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Round-robin</li>
                <li>b) Shortest Job Next</li>
                <li>c) First-come, first-serve</li>
                <li>d) Priority scheduling</li>
            </ul>
            <p><strong>Answer:</strong> b) Shortest Job Next</p>
            <p><strong>Explanation:</strong> The <strong>Shortest Job Next (SJN)</strong> algorithm, also known as Shortest Job First (SJF), selects the process with the shortest estimated execution time to run next. This minimizes the average waiting time for processes, as shorter jobs complete quickly, reducing the queue. However, SJN requires accurate estimation of execution times, which can be challenging in dynamic systems. In contrast, <strong>Round-robin</strong> allocates equal time slices to all processes, <strong>First-come, first-serve (FCFS)</strong> executes processes in arrival order, and <strong>Priority scheduling</strong> uses predefined priorities, which may not be based on execution time.</p>
            <p class="key-concepts">Key Concepts: Shortest Job Next, scheduling, average waiting time, execution time estimation.</p>
        </div>

        <!-- Question 4 -->
        <div class="question">
            <h2>4. Which of the following is an example of a block I/O device?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Keyboard</li>
                <li>b) Mouse</li>
                <li>c) Hard Disk</li>
                <li>d) Printer</li>
            </ul>
            <p><strong>Answer:</strong> c) Hard Disk</p>
            <p><strong>Explanation:</strong> <strong>Block I/O devices</strong> handle data in fixed-size blocks, such as sectors on a hard disk or SSD. Hard disks are classic examples, as they read/write data in blocks (e.g., 512 bytes or 4 KB), making them suitable for file systems and storage management. In contrast, <strong>keyboards</strong> and <strong>mice</strong> are <strong>character stream devices</strong>, producing data as a stream of characters or events. <strong>Printers</strong> typically use serial I/O, sending data sequentially. Understanding the difference between block and character devices is crucial for OS device management.</p>
            <p class="key-concepts">Key Concepts: Block I/O, character stream devices, storage devices, device management.</p>
        </div>

        <!-- Question 5 -->
        <div class="question">
            <h2>5. Which of the following is a benefit of using memory-mapped files in an operating system?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Reduced disk I/O</li>
                <li>b) Reduced CPU usage</li>
                <li>c) Increased memory usage</li>
                <li>d) Increased process isolation</li>
            </ul>
            <p><strong>Answer:</strong> a) Reduced disk I/O</p>
            <p><strong>Explanation:</strong> <strong>Memory-mapped files</strong> allow a file to be mapped directly into a process’s virtual address space, enabling the OS to treat file data as if it were in memory. This reduces the need for explicit disk I/O operations (e.g., read/write system calls), as the OS can load file data into memory on demand via paging. This improves performance, especially for large files. <strong>Reduced CPU usage</strong> is not a primary benefit, as CPU usage depends on the workload. <strong>Increased memory usage</strong> is a potential downside, not a benefit. <strong>Process isolation</strong> is unrelated to memory-mapped files.</p>
            <p class="key-concepts">Key Concepts: Memory-mapped files, virtual memory, disk I/O, paging.</p>
        </div>

        <!-- Question 6 -->
        <div class="question">
            <h2>6. Which of the following is a responsibility of memory management in an operating system?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Allocating and deallocating physical memory</li>
                <li>b) Monitoring physical memory usage</li>
                <li>c) Protecting physical memory from unauthorized access</li>
                <li>d) All of the above</li>
            </ul>
            <p><strong>Answer:</strong> d) All of the above</p>
            <p><strong>Explanation:</strong> Memory management in an OS is responsible for multiple tasks: <strong>allocating and deallocating physical memory</strong> to processes, ensuring efficient use of resources; <strong>monitoring physical memory usage</strong> to track which memory is in use or free; and <strong>protecting physical memory</strong> by using mechanisms like address space isolation and page table permissions to prevent unauthorized access. All these functions are critical for secure and efficient memory usage, making <strong>all of the above</strong> the correct choice.</p>
            <p class="key-concepts">Key Concepts: Memory management, allocation, monitoring, protection, address space isolation.</p>
        </div>

        <!-- Question 7 -->
        <div class="question">
            <h2>7. Which of the following is not a primary function of input/output (I/O) in an operating system?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Data transfer between devices and memory</li>
                <li>b) Device management and control</li>
                <li>c) Process scheduling and synchronization</li>
                <li>d) Interrupt handling and I/O error detection</li>
            </ul>
            <p><strong>Answer:</strong> c) Process scheduling and synchronization</p>
            <p><strong>Explanation:</strong> The primary functions of I/O in an OS include <strong>data transfer</strong> between devices and memory (e.g., reading from a disk), <strong>device management</strong> (e.g., configuring and controlling devices), and <strong>interrupt handling</strong> (e.g., responding to device events) along with error detection. <strong>Process scheduling and synchronization</strong>, however, are functions of the OS’s process management subsystem, not I/O. Scheduling determines which process runs next, and synchronization manages process coordination, which are separate from I/O operations.</p>
            <p class="key-concepts">Key Concepts: I/O management, device management, interrupt handling, process scheduling.</p>
        </div>

        <!-- Question 8 -->
        <div class="question">
            <h2>8. Which of the following is a disadvantage of using demand paging in an operating system?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Increased memory usage</li>
                <li>b) Increased disk I/O</li>
                <li>c) Increased CPU usage</li>
                <li>d) Increased fragmentation</li>
            </ul>
            <p><strong>Answer:</strong> b) Increased disk I/O</p>
            <p><strong>Explanation:</strong> <strong>Demand paging</strong> loads pages into memory only when they are needed, reducing memory usage. However, a key disadvantage is <strong>increased disk I/O</strong>, as pages must be fetched from disk when a page fault occurs. This can slow down performance, especially if page faults are frequent. <strong>Increased memory usage</strong> is not a disadvantage, as demand paging optimizes memory. <strong>Increased CPU usage</strong> may occur indirectly but is not the primary issue. <strong>Fragmentation</strong> is unrelated to demand paging, as it deals with memory allocation patterns.</p>
            <p class="key-concepts">Key Concepts: Demand paging, page fault, disk I/O, virtual memory.</p>
        </div>

        <!-- Question 9 -->
        <div class="question">
            <h2>9. Which of the following is not a benefit of using virtual memory in an operating system?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Increased efficient memory usage</li>
                <li>b) Protection of system resources</li>
                <li>c) Simplified memory allocation</li>
                <li>d) Ability to run larger applications</li>
            </ul>
            <p><strong>Answer:</strong> b) Protection of system resources</p>
            <p><strong>Explanation:</strong> <strong>Virtual memory</strong> provides several benefits: <strong>efficient memory usage</strong> by allowing paging and swapping, <strong>simplified memory allocation</strong> through abstract address spaces, and the <strong>ability to run larger applications</strong> by using disk as extended memory. However, <strong>protection of system resources</strong> is not a direct benefit of virtual memory. While virtual memory supports process isolation (protecting processes from each other), resource protection is a broader OS security function, not specific to virtual memory.</p>
            <p class="key-concepts">Key Concepts: Virtual memory, paging, process isolation, memory allocation.</p>
        </div>

        <!-- Question 10 -->
        <div class="question">
            <h2>10. Which of the following is a benefit of multithreading in operating systems?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Increased parallelism and improved performance</li>
                <li>b) Reduced system resources for each process</li>
                <li>c) Simplified system security management</li>
                <li>d) Elimination of process scheduling</li>
            </ul>
            <p><strong>Answer:</strong> a) Increased parallelism and improved performance</p>
            <p><strong>Explanation:</strong> <strong>Multithreading</strong> allows multiple threads within a process to execute concurrently, sharing the same memory and resources. This enables <strong>increased parallelism</strong> (e.g., on multi-core CPUs) and <strong>improved performance</strong> by utilizing CPU cycles more efficiently. <strong>Reduced system resources</strong> is partially true, as threads share memory, but it’s not the primary benefit. <strong>Simplified security management</strong> is unrelated, as multithreading can complicate security. <strong>Eliminating scheduling</strong> is incorrect, as threads still require scheduling.</p>
            <p class="key-concepts">Key Concepts: Multithreading, parallelism, performance, thread scheduling.</p>
        </div>

        <!-- Question 11 -->
        <div class="question">
            <h2>11. Which of the following is a disadvantage of Direct Memory Access (DMA)?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Low CPU usage</li>
                <li>b) High I/O throughput</li>
                <li>c) Higher latency</li>
                <li>d) None of the above</li>
            </ul>
            <p><strong>Answer:</strong> c) Higher latency</p>
            <p><strong>Explanation:</strong> <strong>Direct Memory Access (DMA)</strong> allows devices to transfer data directly to/from memory without CPU involvement, reducing CPU usage and enabling high I/O throughput. However, a disadvantage is <strong>higher latency</strong> in some cases, due to the setup time for DMA transfers and synchronization overhead. <strong>Low CPU usage</strong> and <strong>high I/O throughput</strong> are benefits, not disadvantages. <strong>None of the above</strong> is incorrect, as higher latency is a valid concern.</p>
            <p class="key-concepts">Key Concepts: DMA, I/O throughput, latency, CPU offloading.</p>
        </div>

        <!-- Question 12 -->
        <div class="question">
            <h2>12. Which of the following is not an advantage of asynchronous I/O?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Increased efficiency</li>
                <li>b) Reduced latency</li>
                <li>c) Simplified programming</li>
                <li>d) None of the above</li>
            </ul>
            <p><strong>Answer:</strong> c) Simplified programming</p>
            <p><strong>Explanation:</strong> <strong>Asynchronous I/O</strong> allows a process to continue executing while I/O operations are performed in the background, leading to <strong>increased efficiency</strong> and potentially <strong>reduced latency</strong> for the process. However, it does not simplify programming; asynchronous I/O often requires complex mechanisms like callbacks, promises, or event loops, making programming more challenging compared to synchronous I/O. <strong>None of the above</strong> is incorrect, as simplified programming is not an advantage.</p>
            <p class="key-concepts">Key Concepts: Asynchronous I/O, efficiency, latency, programming complexity.</p>
        </div>

        <!-- Question 13 -->
        <div class="question">
            <h2>13. Which of the following correctly defines a process in the context of operating systems?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) A program in execution</li>
                <li>b) A file stored on disk</li>
                <li>c) An input/output device</li>
                <li>d) A network communication protocol</li>
            </ul>
            <p><strong>Answer:</strong> a) A program in execution</p>
            <p><strong>Explanation:</strong> A <strong>process</strong> is a program in execution, encompassing the program code, data, stack, and execution state (e.g., registers, program counter). It is the active entity managed by the OS. A <strong>file on disk</strong> is static data, not a process. An <strong>I/O device</strong> is hardware, and a <strong>network protocol</strong> is a communication standard, none of which define a process.</p>
            <p class="key-concepts">Key Concepts: Process, program execution, process state, OS management.</p>
        </div>

        <!-- Question 14 -->
        <div class="question">
            <h2>14. Which of the following is a method used for deadlock detection?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Resource Allocation Graph</li>
                <li>b) Round-Robin Scheduling</li>
                <li>c) Least Recently Used (LRU)</li>
                <li>d) Shortest Job Next</li>
            </ul>
            <p><strong>Answer:</strong> a) Resource Allocation Graph</p>
            <p><strong>Explanation:</strong> A <strong>Resource Allocation Graph (RAG)</strong> is a graphical representation used to detect deadlocks by identifying cycles in resource requests and allocations. A cycle in the graph indicates a potential deadlock. <strong>Round-Robin Scheduling</strong>, <strong>LRU</strong>, and <strong>Shortest Job Next</strong> are scheduling or replacement algorithms, not related to deadlock detection.</p>
            <p class="key-concepts">Key Concepts: Deadlock detection, Resource Allocation Graph, cycles, resource management.</p>
        </div>

        <!-- Question Девятнадцатый -->
        <div class="question">
            <h2>15. Which of the following is a synchronous I/O operation?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Polling</li>
                <li>b) Interrupts</li>
                <li>c) Direct Memory Access (DMA)</li>
                <li>d) None of the above</li>
            </ul>
            <p><strong>Answer:</strong> a) Polling</p>
            <p><strong>Explanation:</strong> <strong>Polling</strong> is a synchronous I/O operation where the CPU repeatedly checks a device’s status to determine if an I/O operation is complete, blocking other tasks. <strong>Interrupts</strong> and <strong>DMA</strong> are asynchronous, as they allow the CPU to perform other tasks while waiting for I/O completion, signaled by an interrupt or managed by a DMA controller. <strong>None of the above</strong> is incorrect, as polling is synchronous.</p>
            <p class="key-concepts">Key Concepts: Synchronous I/O, polling, interrupts, DMA.</p>
        </div>

        <!-- Question 16 -->
        <div class="question">
            <h2>16. Which of the following is not a common file system access control mechanism?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) User-based permissions</li>
                <li>b) Role-based access control</li>
                <li>c) Password protection</li>
                <li>d) Access control lists</li>
            </ul>
            <p><strong>Answer:</strong> c) Password protection</p>
            <p><strong>Explanation:</strong> Common file system access control mechanisms include <strong>user-based permissions</strong> (e.g., owner/group/other in Unix), <strong>role-based access control</strong> (RBAC, assigning permissions to roles), and <strong>access control lists</strong> (ACLs, specifying permissions for specific users). <strong>Password protection</strong> is used for securing files or systems but is not a standard file system access control mechanism, as it typically applies to authentication, not file-level permissions.</p>
            <p class="key-concepts">Key Concepts: File system access control, user-based permissions, RBAC, ACLs.</p>
        </div>

        <!-- Question 17 -->
        <div class="question">
            <h2>17. Which of the following is not a common file system error correction mechanism?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Journaling</li>
                <li>b) Checksum</li>
                <li>c) Backups</li>
                <li>d) Randomization</li>
            </ul>
            <p><strong>Answer:</strong> d) Randomization</p>
            <p><strong>Explanation:</strong> <strong>Journaling</strong> records file system changes to ensure consistency after crashes, <strong>checksums</strong> detect data corruption, and <strong>backups</strong> restore data after errors. These are common error correction mechanisms. <strong>Randomization</strong> is not related to error correction; it may refer to techniques like address space layout randomization (ASLR) for security, not file system reliability.</p>
            <p class="key-concepts">Key Concepts: File system reliability, journaling, checksum, backups.</p>
        </div>

        <!-- Question 18 -->
        <div class="question">
            <h2>18. Which technique is used by operating systems to reclaim memory no longer needed by a process?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Paging</li>
                <li>b) Swap</li>
                <li>c) Garbage collection</li>
                <li>d) Fragmentation</li>
            </ul>
            <p><strong>Answer:</strong> c) Garbage collection</p>
            <p><strong>Explanation:</strong> <strong>Garbage collection</strong> is a technique used to reclaim memory that a process no longer needs, automatically freeing unused memory objects (common in languages like Java). <strong>Paging</strong> manages memory allocation, <strong>swap</strong> moves pages to disk, and <strong>fragmentation</strong> is a problem where memory becomes inefficiently allocated, none of which directly reclaim unused memory.</p>
            <p class="key-concepts">Key Concepts: Garbage collection, memory reclamation, memory management.</p>
        </div>

        <!-- Question 19 -->
        <div class="question">
            <h2>19. What is a page fault in the context of memory management?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) An error when there is insufficient physical memory to run an application</li>
                <li>b) A mechanism for allocating memory to applications</li>
                <li>c) An error when an application accesses memory not loaded in physical memory</li>
                <li>d) None of the above</li>
            </ul>
            <p><strong>Answer:</strong> c) An error when an application accesses memory not loaded in physical memory</p>
            <p><strong>Explanation:</strong> A <strong>page fault</strong> occurs when a process attempts to access a virtual memory page that is not currently in physical memory (e.g., it’s in swap space or not yet loaded). The OS handles the fault by loading the required page, possibly evicting another. <strong>Insufficient memory</strong> may cause thrashing, not a page fault. <strong>Memory allocation</strong> is a separate process. <strong>None of the above</strong> is incorrect.</p>
            <p class="key-concepts">Key Concepts: Page fault, virtual memory, paging, swap space.</p>
        </div>

        <!-- Question 20 -->
        <div class="question">
            <h2>20. What is a Translation Lookaside Buffer (TLB) in the context of memory management?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) A mechanism to protect memory in an operating system</li>
                <li>b) A data structure to store information about physical memory</li>
                <li>c) An error when there is insufficient physical memory</li>
                <li>d) A hardware component that caches frequently used virtual-to-physical address translations</li>
            </ul>
            <p><strong>Answer:</strong> d) A hardware component that caches frequently used virtual-to-physical address translations</p>
            <p><strong>Explanation:</strong> The <strong>Translation Lookaside Buffer (TLB)</strong> is a hardware cache in the CPU that stores recent virtual-to-physical address translations, speeding up memory access by reducing page table lookups. It’s not a <strong>protection mechanism</strong>, a <strong>data structure</strong> (though it holds data), or an <strong>error</strong>. TLB misses require slower page table access, impacting performance.</p>
            <p class="key-concepts">Key Concepts: TLB, address translation, virtual memory, performance.</p>
        </div>

        <!-- Question 21 -->
        <div class="question">
            <h2>21. What is thrashing in the context of memory management?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) A process consuming excessive CPU time</li>
                <li>b) Frequent page faults</li>
                <li>c) A process causing memory leaks</li>
                <li>d) A process exceeding its allocated memory quota</li>
            </ul>
            <p><strong>Answer:</strong> b) Frequent page faults</p>
            <p><strong>Explanation:</strong> <strong>Thrashing</strong> occurs when the OS spends excessive time swapping pages between physical memory and disk due to frequent page faults, often because too many processes are competing for limited memory. This degrades performance, as the CPU is underutilized. <strong>Excessive CPU time</strong>, <strong>memory leaks</strong>, and <strong>exceeding quotas</strong> are distinct issues unrelated to thrashing.</p>
            <p class="key-concepts">Key Concepts: Thrashing, page faults, virtual memory, performance degradation.</p>
        </div>

        <!-- Question 22 -->
        <div class="question">
            <h2>22. What is the purpose of directory entries in a file system?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) To store actual file data</li>
                <li>b) To store metadata about a file</li>
                <li>c) To track the physical location of a file on disk</li>
                <li>d) To provide file access permissions</li>
            </ul>
            <p><strong>Answer:</strong> b) To store metadata about a file</p>
            <p><strong>Explanation:</strong> <strong>Directory entries</strong> store metadata about files, such as file name, size, creation date, and pointers to the file’s data blocks. While they may include information about <strong>physical location</strong> (via inode pointers) and <strong>permissions</strong>, their primary purpose is to hold metadata. <strong>Actual file data</strong> is stored in separate data blocks on the disk.</p>
            <p class="key-concepts">Key Concepts: Directory entries, file metadata, file system structure.</p>
        </div>

        <!-- Question 23 -->
        <div class="question">
            <h2>23. What is the primary purpose of memory management in an operating system?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) To ensure efficient and reliable execution of applications</li>
                <li>b) To manage network connections</li>
                <li>c) To control power consumption</li>
                <li>d) To encrypt data stored in memory</li>
            </ul>
            <p><strong>Answer:</strong> a) To ensure efficient and reliable execution of applications</p>
            <p><strong>Explanation:</strong> The primary purpose of <strong>memory management</strong> is to allocate, track, and protect memory to ensure applications run efficiently and reliably. This includes virtual memory, paging, and process isolation. <strong>Network management</strong>, <strong>power control</strong>, and <strong>encryption</strong> are handled by other OS components, not memory management.</p>
            <p class="key-concepts">Key Concepts: Memory management, efficient execution, process isolation.</p>
        </div>

        <!-- Question 24 -->
        <div class="question">
            <h2>24. What is the difference between a process and a thread?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) A process is a single execution unit, while a thread is a collection of related processes</li>
                <li>b) A process is a collection of related threads, while a thread is a single execution unit</li>
                <li>c) There is no difference between a process and a thread</li>
                <li>d) A process is used in single-tasking systems, while a thread is used in multitasking systems</li>
            </ul>
            <p><strong>Answer:</strong> b) A process is a collection of related threads, while a thread is a single execution unit</p>
            <p><strong>Explanation:</strong> A <strong>process</strong> is a program in execution, containing one or more <strong>threads</strong>, which are the smallest units of execution. Threads within a process share the same memory and resources but have separate stacks and registers. <strong>Option a</strong> reverses the definitions. <strong>Option c</strong> is incorrect, as processes and threads are distinct. <strong>Option d</strong> is wrong, as both are used in multitasking systems.</p>
            <p class="key-concepts">Key Concepts: Process, thread, multithreading, resource sharing.</p>
        </div>

        <!-- Question 25 -->
        <div class="question">
            <h2>25. What is the primary advantage of using a journaling file system?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Faster file access times</li>
                <li>b) Improved data compression</li>
                <li>c) Faster file system recovery after crashes</li>
                <li>d) Enhanced file sharing capabilities</li>
            </ul>
            <p><strong>Answer:</strong> c) Faster file system recovery after crashes</p>
            <p><strong>Explanation:</strong> A <strong>journaling file system</strong> logs changes before applying them, enabling <strong>faster recovery</strong> after crashes by replaying or undoing logged operations to restore consistency. <strong>Faster access times</strong> and <strong>compression</strong> are not primary benefits, as journaling may slightly increase overhead. <strong>File sharing</strong> is unrelated to journaling.</p>
            <p class="key-concepts">Key Concepts: Journaling, file system recovery, consistency.</p>
        </div>

        <!-- Question 26 -->
        <div class="question">
            <h2>26. Which scheduling algorithm aims to give each process an equal share of CPU time?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Round-robin</li>
                <li>b) Shortest Job Next</li>
                <li>c) First-come, first-serve</li>
                <li>d) Priority scheduling</li>
            </ul>
            <p><strong>Answer:</strong> a) Round-robin</p>
            <p><strong>Explanation:</strong> <strong>Round-robin</strong> scheduling assigns each process a fixed time slice (quantum) in a cyclic order, ensuring equal CPU time sharing. <strong>Shortest Job Next</strong> prioritizes short tasks, <strong>FCFS</strong> follows arrival order, and <strong>Priority scheduling</strong> favors high-priority processes, none of which guarantee equal shares.</p>
            <p class="key-concepts">Key Concepts: Round-robin, time quantum, fair scheduling.</p>
        </div>

        <!-- Question 27 -->
        <div class="question">
            <h2>27. Which I/O technique allows a process to perform other tasks while waiting for I/O completion?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Polling</li>
                <li>b) Interrupt-driven I/O</li>
                <li>c) Direct Memory Access (DMA)</li>
                <li>d) Programmed I/O</li>
            </ul>
            <p><strong>Answer:</strong> b) Interrupt-driven I/O</p>
            <p><strong>Explanation:</strong> <strong>Interrupt-driven I/O</strong> allows the CPU to perform other tasks while an I/O operation is in progress, with the device signaling completion via an interrupt. <strong>Polling</strong> ties up the CPU checking device status. <strong>DMA</strong> offloads I/O to a controller but is a separate mechanism. <strong>Programmed I/O</strong> requires CPU involvement, blocking other tasks.</p>
            <p class="key-concepts">Key Concepts: Interrupt-driven I/O, asynchronous I/O, CPU utilization.</p>
        </div>

        <!-- Question 28 -->
        <div class="question">
            <h2>28. Which I/O technique allows data transfer between devices and memory without CPU involvement?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Polling</li>
                <li>b) Interrupt-driven I/O</li>
                <li>c) Direct Memory Access (DMA)</li>
                <li>d) Programmed I/O</li>
            </ul>
            <p><strong>Answer:</strong> c) Direct Memory Access (DMA)</p>
            <p><strong>Explanation:</strong> <strong>DMA</strong> enables direct data transfer between devices and memory via a DMA controller, bypassing the CPU to improve efficiency for large data transfers. <strong>Polling</strong>, <strong>Interrupt-driven I/O</strong>, and <strong>Programmed I/O</strong> all involve the CPU in data transfer.</p>
            <p class="key-concepts">Key Concepts: DMA, CPU offloading, I/O efficiency.</p>
        </div>

        <!-- Question 29 -->
        <div class="question">
            <h2>29. Which page replacement algorithm aims to minimize page faults by selecting the page unused for the longest time?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Least Recently Used (LRU)</li>
                <li>b) First-In, First-Out (FIFO)</li>
                <li>c) Optimal</li>
                <li>d) Clock</li>
            </ul>
            <p><strong>Answer:</strong> a) Least Recently Used (LRU)</p>
            <p><strong>Explanation:</strong> <strong>LRU</strong> replaces the page that has not been accessed for the longest time, assuming it’s least likely to be needed soon. This minimizes page faults but requires tracking page access history. <strong>FIFO</strong> replaces the oldest page, <strong>Optimal</strong> selects the page not needed furthest in the future, and <strong>Clock</strong> uses a reference bit for approximation.</p>
            <p class="key-concepts">Key Concepts: LRU, page replacement, page faults.</p>
        </div>

        <!-- Question 30 -->
        <div class="question">
            <h2>30. Which page replacement algorithm suffers from Belady’s anomaly, where increasing the number of page frames can increase page faults?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Least Recently Used (LRU)</li>
                <li>b) First-In, First-Out (FIFO)</li>
                <li>c) Optimal</li>
                <li>d) Clock</li>
            </ul>
            <p><strong>Answer:</strong> b) First-In, First-Out (FIFO)</p>
            <p><strong>Explanation:</strong> <strong>Belady’s anomaly</strong> occurs when adding more page frames increases page faults, counterintuitively. <strong>FIFO</strong> is prone to this because it replaces pages based on arrival order, not usage patterns, leading to poor decisions in some access sequences. <strong>LRU</strong>, <strong>Optimal</strong>, and <strong>Clock</strong> are less susceptible or immune to this anomaly.</p>
            <p class="key-concepts">Key Concepts: Belady’s anomaly, FIFO, page replacement.</p>
        </div>

        <!-- Question 31 -->
        <div class="question">
            <h2>31. Which technique allows applications to access a larger address space than physically available in a computer’s memory?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Virtual memory</li>
                <li>b) Segmentation</li>
                <li>c) Paging</li>
                <li>d) Fragmentation</li>
            </ul>
            <p><strong>Answer:</strong> a) Virtual memory</p>
            <p><strong>Explanation:</strong> <strong>Virtual memory</strong> allows applications to use a larger address space by abstracting physical memory and using disk-based swap space. <strong>Paging</strong> and <strong>segmentation</strong> are mechanisms within virtual memory, but virtual memory is the overarching technique. <strong>Fragmentation</strong> is a memory management issue, not a solution.</p>
            <p class="key-concepts">Key Concepts: Virtual memory, address space, swap space.</p>
        </div>

        <!-- Question 32 -->
        <div class="question">
            <h2>32. Which scheduling algorithm assigns priorities to processes based on their characteristics or importance?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Round-robin</li>
                <li>b) Shortest Job Next</li>
                <li>c) First-come, first-serve</li>
                <li>d) Priority scheduling</li>
            </ul>
            <p><strong>Answer:</strong> d) Priority scheduling</p>
            <p><strong>Explanation:</strong> <strong>Priority scheduling</strong> assigns priorities to processes based on factors like importance, resource needs, or deadlines, executing higher-priority processes first. <strong>Round-robin</strong> uses equal time slices, <strong>Shortest Job Next</strong> prioritizes short execution times, and <strong>FCFS</strong> follows arrival order.</p>
            <p class="key-concepts">Key Concepts: Priority scheduling, process prioritization.</p>
        </div>

        <!-- Question 33 -->
        <div class="question">
            <h2>33. What is the main disadvantage of the First-Come, First-Serve (FCFS) scheduling algorithm?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Long waiting times for short processes</li>
                <li>b) Preference for CPU-bound processes over I/O-bound processes</li>
                <li>c) Lack of support for preemptive scheduling</li>
                <li>d) Requirement for complex priority calculations</li>
            </ul>
            <p><strong>Answer:</strong> a) Long waiting times for short processes</p>
            <p><strong>Explanation:</strong> <strong>FCFS</strong> executes processes in arrival order, which can lead to the <strong>convoy effect</strong>: a long-running process delays subsequent short processes, causing long waiting times. <strong>Preference for CPU-bound processes</strong> is not inherent to FCFS. <strong>Non-preemptive</strong> nature is a limitation but not the main disadvantage. <strong>Complex calculations</strong> are not required, as FCFS is simple.</p>
            <p class="key-concepts">Key Concepts: FCFS, convoy effect, waiting time.</p>
        </div>

        <!-- Question 34 -->
        <div class="question">
            <h2>34. Which strategy can be used to prevent deadlocks?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Resource Allocation Graph</li>
                <li>b) Banker’s Algorithm</li>
                <li>c) Rollback</li>
                <li>d) Preemption</li>
            </ul>
            <p><strong>Answer:</strong> b) Banker’s Algorithm</p>
            <p><strong>Explanation:</strong> The <strong>Banker’s Algorithm</strong> prevents deadlocks by ensuring resource allocation avoids unsafe states, checking if granting a resource request leads to a deadlock-prone state. <strong>Resource Allocation Graph</strong> detects deadlocks, <strong>rollback</strong> recovers from them, and <strong>preemption</strong> resolves them, but none prevent deadlocks proactively like the Banker’s Algorithm.</p>
            <p class="key-concepts">Key Concepts: Banker’s Algorithm, deadlock prevention, resource allocation.</p>
        </div>

        <!-- Question 35 -->
        <div class="question">
            <h2>35. Which page does the Optimal page replacement algorithm select for replacement?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) The page that will cause the fewest page faults in the future</li>
                <li>b) The most recently accessed page</li>
                <li>c) The page not accessed recently</li>
                <li>d) The highest priority page</li>
            </ul>
            <p><strong>Answer:</strong> a) The page that will cause the fewest page faults in the future</p>
            <p><strong>Explanation:</strong> The <strong>Optimal</strong> page replacement algorithm selects the page that will not be needed for the longest time in the future, minimizing page faults. It’s theoretical, as it requires future knowledge. <strong>Recent access</strong> or <strong>priority</strong> are not criteria. <strong>Not accessed recently</strong> describes LRU, not Optimal.</p>
            <p class="key-concepts">Key Concepts: Optimal page replacement, page faults, future prediction.</p>
        </div>

        <!-- Question 36 -->
        <div class="question">
            <h2>36. The Clock page replacement algorithm maintains a circular list of pages and uses which mechanism to determine which page to replace?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Reference bit</li>
                <li>b) Dirty bit</li>
                <li>c) Page size</li>
                <li>d) Page priority</li>
            </ul>
            <p><strong>Answer:</strong> a) Reference bit</p>
            <p><strong>Explanation:</strong> The <strong>Clock</strong> algorithm uses a <strong>reference bit</strong> to track whether a page has been accessed. Pages are arranged in a circular list, and a pointer moves through them. If a page’s reference bit is 1 (recently used), it’s cleared, and the pointer moves on. If it’s 0, the page is replaced. <strong>Dirty bit</strong> tracks modifications, <strong>page size</strong> is irrelevant, and <strong>priority</strong> is not used.</p>
            <p class="key-concepts">Key Concepts: Clock algorithm, reference bit, page replacement.</p>
        </div>

        <!-- Question 37 -->
        <div class="question">
            <h2>37. Which mechanism is used in virtual memory to translate virtual addresses to physical addresses?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Page tables</li>
                <li>b) Segmentation</li>
                <li>c) Demand paging</li>
                <li>d) Translation Lookaside Buffer (TLB)</li>
            </ul>
            <p><strong>Answer:</strong> a) Page tables</p>
            <p><strong>Explanation:</strong> <strong>Page tables</strong> map virtual addresses to physical addresses in virtual memory systems, maintained by the OS and used by the MMU. <strong>Segmentation</strong> is an alternative memory management technique. <strong>Demand paging</strong> loads pages on demand, not translation. <strong>TLB</strong> caches translations for speed but is not the primary mechanism.</p>
            <p class="key-concepts">Key Concepts: Page tables, address translation, virtual memory.</p>
        </div>

        <!-- Question 38 -->
        <div class="question">
            <h2>38. Which technique is commonly used to manage memory sharing between multiple applications in virtual memory systems?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Demand paging</li>
                <li>b) Page replacement algorithms</li>
                <li>c) Segmentation</li>
                <li>d) Copy-on-write</li>
            </ul>
            <p><strong>Answer:</strong> d) Copy-on-write</p>
            <p><strong>Explanation:</strong> <strong>Copy-on-write (COW)</strong> allows multiple processes to share the same memory pages until one attempts to modify a page, at which point a copy is made. This optimizes memory usage for shared libraries or forked processes. <strong>Demand paging</strong> and <strong>page replacement</strong> manage memory allocation, not sharing. <strong>Segmentation</strong> organizes memory but doesn’t address sharing directly.</p>
            <p class="key-concepts">Key Concepts: Copy-on-write, memory sharing, virtual memory.</p>
        </div>

        <!-- Question 39 -->
        <div class="question">
            <h2>39. What is the role of a page replacement algorithm?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) To determine which memory pages to allocate to an application</li>
                <li>b) To determine which memory pages to free from an application</li>
                <li>c) To determine which memory pages to move to disk to free physical memory</li>
                <li>d) To determine which memory pages to move from disk to physical memory</li>
            </ul>
            <p><strong>Answer:</strong> c) To determine which memory pages to move to disk to free physical memory</p>
            <p><strong>Explanation:</strong> A <strong>page replacement algorithm</strong> selects which page in physical memory to evict (move to swap space) when a new page must be loaded and memory is full. This frees space for the incoming page. <strong>Allocation</strong> is handled by memory management, <strong>freeing</strong> is broader, and <strong>moving from disk</strong> occurs after replacement.</p>
            <p class="key-concepts">Key Concepts: Page replacement, swap space, memory management.</p>
        </div>

        <!-- Question 40 -->
        <div class="question">
            <h2>40. Which scheduling algorithm provides the minimum average waiting time for all processes?</h2>
            <p><strong>Options:</strong></p>
            <ul>
                <li>a) Round-robin</li>
                <li>b) Shortest Job Next</li>
                <li>c) First-come, first-serve</li>
                <li>d) Shortest Remaining Time First (SRTF)</li>
            </ul>
            <p><strong>Answer:</strong> d) Shortest Remaining Time First (SRTF)</p>
            <p><strong>Explanation:</strong> <strong>SRTF</strong> is a preemptive version of Shortest Job Next, always executing the process with the shortest remaining execution time. This minimizes average waiting time by prioritizing short tasks and preempting longer ones. <strong>Round-robin</strong> ensures fairness but not minimal waiting. <strong>SJN</strong> is non-preemptive, less optimal. <strong>FCFS</strong> can cause long waits due to the convoy effect.</p>
            <p class="key-concepts">Key Concepts: SRTF, average waiting time, preemptive scheduling.</p>
        </div>
    </div>
</body>
</html>